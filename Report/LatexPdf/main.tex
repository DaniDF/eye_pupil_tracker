%Questo è il preambolo, dove si inseriscono i pacchetti e le impostazioni che servono per compilare il documento. Quanto scritto dopo il simbolo '%' è solo un commento e serve a fini dimostrativi.

\documentclass[11pt]{article}
\linespread{1.6} %interlinea
\pagestyle{plain}
\usepackage{geometry} %margini
\geometry{a4paper, top=3cm, bottom=3cm, left=3cm, right=3cm, bindingoffset=5mm}
\usepackage{graphicx}
\graphicspath{immagini/}
\usepackage{multicol} %più colonne
\usepackage{ragged2e} %allineamento testo

\usepackage[italian]{babel} %lingua principale

\usepackage{minitoc} %mini sommario a inizio capitolo
\nomtcrule 
\addto{\captionsitalian}{% Making babel aware of special titles
  \renewcommand{\mtctitle}{Sommario}
}




\usepackage[sorting=none,backend=biber]{biblatex} %bibliografia
\defbibheading{bibbysubsect}{\section*{}}
\addbibresource{bibliografia.bib}






\usepackage{comment}



\begin{comment}


\renewcommand{\familydefault}{\sfdefault}



\end{comment}



    


    


    








\usepackage{xpatch}
\usepackage{blindtext}
\usepackage{url}


\makeatletter

\xpatchcmd{\@makeschapterhead}{%
  \Huge \bfseries  #1\par\nobreak%
}{%
  \Huge \bfseries\centering #1\par\nobreak%
}{\typeout{Patched makeschapterhead}}{\typeout{patching of @makeschapterhead failed}}


\xpatchcmd{\@makechapterhead}{%
  \huge\bfseries \@chapapp\space \thechapter
}{%
  \huge\bfseries\centering \@chapapp\space \thechapter
}{\typeout{Patched @makechapterhead}}{\typeout{Patching of @makechapterhead failed}}

\makeatother

\usepackage{fancyhdr}
\usepackage[export]{adjustbox}



\usepackage{hyperref} %hyperlink
\hypersetup{
    colorlinks=true,
    citecolor=cyan,
    linkcolor=black,
    urlcolor=black,
    pdftitle=TesiFilippoVeronesi,
    pdfauthor= Filippo Veronesi,
    }

\usepackage{booktabs} %per le tabelle
\usepackage{multirow}
\usepackage[table,xcdraw]{xcolor}
\usepackage{graphicx}

\usepackage{lscape}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{epigraph}
\usepackage{fancyhdr}
%Da qui in poi inizia il documento.
\begin{document}
\begin{titlepage} %Cambia i valori in \vspace{} per ottenere un risultato perfetto

\begin{center}
	{\upshape\Large\bfseries ALMA MATER STUDIORUM - UNIVERSITÀ \\ DI BOLOGNA \par}

	\vspace{0,8cm}
		\hrule
	\vspace{0,9cm}
	\vspace{0,3cm}
	{\upshape\small DIPARTIMENTO DI INFORMATICA - SCIENZA E INGEGNERIA\par} 
	\vspace{0,2cm}
	\vspace{0.5cm}
	
	\vspace{1,4cm}
	{\upshape\large\bfseries PROGETTO E ATTIVITÀ PROGETTUALE IN SISTEMI DIGITALI M\par}
	
			
	\vspace{2.3cm}

	{\upshape\large\bfseries EYE TRACKER\par}
	\vspace{2.5cm}
	{\upshape\large\bfseries Luigi di Nuzzo - Daniele Foschi - Filippo Veronesi\par}
	\end{center}
	
	
	
	\vfill
	\hrule
% Bottom of the page
	{\begin{center}
	\vspace{0.3cm}
	     \schape\large Anno Accademico 2021/2022 \\
	     \schape\large Maggio 2022
	\end{center}}

\end{titlepage}


\fancyhf{}
\pagestyle{fancy}
\newcommand{\headeright}{PROGETTO E ATTIVITÀ PROGETTUALE SISTEMI DIGITALI M}
\renewcommand{\headrulewidth}{0.4pt}
\fancyheadoffset{0pt}
\fancyhead[R]{Overleaf}
\renewcommand{\footrulewidth}{0.4pt}

\fancyfoot[R]{Luigi di Nuzzo - Daniele Foschi - Filippo Veronesi}
\rhead{\scshape \footnotesize \headeright}
\chead{\shorttitle}






\clearpage
\null
\thispagestyle{empty}
\clearpage

\newpage







\cleardoublepage



\newpage

\tableofcontents


\newpage


\listoffigures



\newpage


\newpage
\fancyfoot[L]{\thepage}
\setcounter{page}{1}
\section{Introduzione}
Questo progetto prevede la realizzazione di un applicativo Android che, sfruttando una rete neurale,
sia in grado di riconoscere il volto dell’utente e di questo ultimo, anche i propri occhi. Il sistema sfrutterà un modello di rete neurale
addestrato in modo tale da essere in grado di riconoscere i visi e gli occhi di uno o più utenti grazie ad un dataset di 10 mila immagini di visi umani.
L’applicativo permetterà sia di svolgere un filtraggio "live", cioè aprendo la camera frontale ed esterna dello smartphone
e individuando real-time la faccia e gli occhi dell’utente, !!!! sia uno “statico” in cui si selezionano dalla galleria
una foto e in output vengono riconosciuti gli occhi !!!! DA VEDERE SE METTERE. !!!!!
\newline
Inoltre, è stato implementato un gioco (SPIEGAZIONE) aiutato da un tool di calibrazione.
\newline \newline
Tale caso di studio è un classico esempio di applicazione di machine learning e il software farà ricorso
a una rete neurale convoluzionale (CNN). Tale scelta è dovuta al fatto che una rete neurale
rappresenta il modo più comodo e pratico per problemi di object detection, come quello di questa
attività in cui vengono individuati gli occhi.
\newline \newline
L’applicativo, inoltre, è pensato per la piattaforma Android e quindi tale progetto pone attenzione
anche all’uso di risorse in quanto dovrà funzionare su smartphone, ovvero dispositivi embedded.

\newpage

\section{Rete Neurale}
L’obbiettivo primario di questo task è produrre un modello di rete neurale addestrata in grado di
riconoscere gli occhi di una o più persone. A tal scopo si è utilizzato un modello messo a disposizione dalla libreria
TensorFlow ottimizzato per il training di modelli specifici per object detection di immagini. Visto
l’ambito dei sistemi embedded nel quale il progetto complessivo si colloca si è optato per ResNet e MobileNet,
una CNN pensata per dispositivi mobile. MobileNet è il primo modello di computer vision pensato
per dispositivi embedded basato su TensorFlow. MobileNet è sufficientemente leggera e veloce da
essere eseguita su smartphone senza consumo di risorse eccessivo mantenendo comunque una
precisione adeguata.


\subsection{Dataset}
Per il training del modello si è utilizzato un dataset pubblico rilasciato da Google (LINK DA INSERIRE) contenente 10 mila immagini di visi umani, dove ogni foto conteneva da uno a più visi umani.
\newline
Oltre alle immagini il dataset conteneva un utile file Excel che indicava le coordinate della posizione degli occhi delle persone all'interno dell'immagine.
\newline \newline
Prima dell'addestramento della rete era però necessario convertire questi dati di input in file XML in modo tale da poterli poi convertire in TFRecord, utili per TensorFlow. Per questo motivo è stato implementato uno script Java in grado di creare un file XML per ogni foto del dataset con al suo interno le informazioni geografiche della posizione degli occhi. 


\subsection{Training}
Si è quindi proceduto all’addestramento della rete
tramite Python usando TensorFlow e le API di Keras. Si è ottenuto in output un modello addestrato
e pronto all’uso. 
\newline \newline
Prima di testare direttamente su Android, abbiamo deciso prima di testare e analizzare la nostra nuova rete utilizzando la libreria Matplotlib, utile per visualizzare graficamente via shell i nostri risultati. In particolare abbiamo usato Tkinter, l'unico framework GUI incluso nella libreria standard di Python.
\newline
A fini di testing si è preso ad esempio il volto di un
personaggio pubblico, quello di Barack Obama, e anche un'immagine contenente più persone in modo tale da poter verificare la correttezza e la precisione della rete anche in condizioni più difficili. (INSERIRE FOTO GUI tkAgg OBAMA e PIU PERSONE)


\subsection{TFLite}
Dopo esserci accertati che la rete funzionasse correttamente e avesse dei livelli di precisione sopra una certa soglia, si è ottenuto in output un modello addestrato
e pronto all’uso, che poi è stato convertito in un formato adatto ai sistemi embedded, quello di TensorFlow Lite.


\newpage
\section{Progetto Android}
L'applicazione Android una volta avviata presenta la seguente interfaccia:
\begin{figure}[h]
\caption{Homepage App }
\centering
\includegraphics[scale=0.2]{img/home.png}
\end{figure}

Sono da segnalare i 3 principali bottoni dell'applicazione:
\begin{itemize}
\item Nerd Mode in alto a destra;
\item Calibration in alto a sinistra;
\item Play Game al centro dello schermo.
\end{itemize}

\subsection{Nerd Mode}
Modalità la cui utilità è quella di individuare real time gli occhi della persona, in particolare permette di vedere i boxes creati dalla rete neruale attorno agli occhi dell'utente.
\\Interfaccia che presenta diversi bottoni:
\begin{itemize}
    \item Preview che permette di avviare la propria fotocamera frontale o esterna;
    \item Analyze che permette appunto la visualizzazione dei boxes creati dalla rete neurale in real time.
    \item Fotocamera frontale/esterna per cambiare da una fotocamera all'altra.
\end{itemize}
\subsubsection{Bottone Analyze}


\subsection{Calibration}
Modalità usata per calibrare al meglio la fotocamera e ottenere risultati i più veritieri possibili. Qui di sotto la sua schermata.


\begin{figure}[h]
\caption{Schermata Calibration }
\centering
\includegraphics[scale=0.2]{img/calibration.png}
\end{figure}


\newpage
\subsection{Game}
Modalità usata per completare un mini-gioco sfruttando le potenzialità della rete neurale sottostante. Tramite un mini gioco Quiz infatti, l'utente può rispondere alle domande del Quiz semplicemente spostando lo sguardo sulle possibili risposte e soffermandosi il più tempo possibile sulla sua scelta. I dati delle domande e delle risposte sono state recuperate da uno dei tanti servizi di Api pubblici che si trovano in rete: tramite appunto una richiesta Url, vengono ricevuti i dati casuali in formato JSON per una singola domanda, e una volta ricevuta la risposta, corretta o sbagliata che sia, viene generata un'altra richiesta in modo tale da poter continuare il mini gioco. 
\begin{figure}[h]
	\centering
	\caption{Schermata Game}
	\includegraphics[scale=0.2]{img/game.png}
\end{figure}







\newpage
\section{Conclusioni}
Gli obiettivi del progetto sono stati raggiunti a pieno e con risultati soddisfacenti. 
\newline \newline
L’applicativo è
conforme alle aspettative e svolge i compiti adeguatamente.
Le parti realizzate
in Android risultano con prestazione adeguate.
\newline \newline
Il modello addestrato restituisce un output corretto la maggior parte delle volte con una precisione di eye tracking del 95\%.





\end{document}
